# Production Configuration for Code Graph RAG MCP
# This file contains production-optimized settings
# Inherits from default.yaml and overrides specific values

# Environment settings
environment: production
debug: false

# MCP Server Configuration (Production Optimized)
mcp:
  embedding:
    # Production embedding configuration
    model: "text-embedding-3-small"  # OpenAI's latest embedding model
    provider: "openai"               # Use OpenAI for production embeddings
    enabled: true                    # Enable embedding in production
    fallbackToMemory: true          # Always have fallback for reliability
    # apiKey configured via environment variable MCP_EMBEDDING_API_KEY
    
    # OpenAI specific configuration
    openai:
      maxBatchSize: 256
    
  server:
    host: "0.0.0.0"     # Accept connections from any interface
    port: 8080          # Standard HTTP port for containers
    timeout: 60000      # 60 seconds timeout for production workloads
    
  agents:
    maxConcurrent: 10   # Higher concurrency for production
    defaultTimeout: 30000  # 30 seconds for complex operations
    useParser: true     # Enable ParserAgent for AST parsing (MCP_USE_PARSER)
    devIndexBatch: 100  # Batch size for file processing (MCP_DEV_INDEX_BATCH)

# Database Configuration (Production Optimized)
database:
  path: "/data/vectors.db"  # Persistent volume path
  mode: "WAL"               # WAL mode for best performance
  cacheSize: 50000          # Larger cache for production
  mmapSize: 1073741824      # 1GB memory mapping for large datasets
  synchronous: "NORMAL"     # Balance between performance and safety
  tempStore: "MEMORY"       # Keep temp data in memory

# Logging Configuration (Production)
logging:
  level: "warn"             # Only warnings and errors in production
  format: "json"            # Structured JSON logging for log aggregation
  enableConsole: false      # Disable console output in production
  outputFile: "/logs/mcp-server.log"  # Persistent log file
  maxFileSize: "100MB"      # Larger log files for production
  maxFiles: 10              # Keep more log files for debugging

# Parser Configuration (Production Optimized)
parser:
  treeSitter:
    enabled: true
    languageConfigs:
      - "typescript"
      - "javascript"
      - "python"
      - "c"
      - "cpp"
      - "java"
      - "rust"
      - "go"
      - "php"
      - "ruby"
      - "swift"
      - "kotlin"
    maxFileSize: 5242880      # 5MB maximum file size for production
    timeout: 10000            # 10 seconds timeout for large files
    
  incremental:
    enabled: true
    cacheSize: 5000           # Larger cache for production workloads
    cacheTTL: 1800000         # 30 minutes cache TTL

# Indexer Configuration
indexer:
  maxConcurrency: 2       # Database write operations
  memoryLimit: 512        # MB for graph operations
  priority: 7
  batchSize: 1000
  cacheSize: 52428800     # 50MB cache (in bytes)
  cacheTTL: 300000        # 5 minutes (in ms)

# Dev Agent Configuration
devAgent:
  maxConcurrency: 3
  memoryLimit: 256
  priority: 7

# Dora Agent Configuration
doraAgent:
  maxConcurrency: 2
  memoryLimit: 128
  priority: 6

# Query Agent Configuration
queryAgent:
  maxConcurrency: 12
  memoryLimit: 128
  priority: 9
  simpleQueryTimeout: 100
  complexQueryTimeout: 1000
  cacheWarmupSize: 150

# Semantic Agent Configuration
semanticAgent:
  maxConcurrency: 6
  memoryLimit: 256
  priority: 8
  batchSize: 16
  modelPath: "./models"

# Coordinator Agent Configuration
coordinator:
  maxConcurrency: 120
  memoryLimit: 128
  priority: 10
  taskQueueLimit: 120
  loadBalancingStrategy: "least-loaded"
  resourceConstraints:
    maxMemoryMB: 2048
    maxCpuPercent: 80
    maxConcurrentAgents: 10
    maxTaskQueueSize: 120

# Conductor Orchestrator Configuration
conductor:
  maxConcurrency: 120
  memoryLimit: 128
  priority: 10
  taskQueueLimit: 120
  loadBalancingStrategy: "least-loaded"
  resourceConstraints:
    maxMemoryMB: 2048
    maxCpuPercent: 80
    maxConcurrentAgents: 10
    maxTaskQueueSize: 120
  complexityThreshold: 8
  mandatoryDelegation: true

# Performance Configuration (Production)
performance:
  monitoring:
    enabled: true
    collectMetrics: true
    metricsInterval: 300000   # 5 minutes metrics collection
    
  optimization:
    enableVectorSearch: true  # Enable vector search in production
    enableParallelParsing: true
    maxWorkerThreads: 8       # More threads for production servers
    
# Production Security
security:
  enableCORS: false           # Disable CORS for production API
  rateLimiting:
    enabled: true
    requestsPerMinute: 1000   # Rate limit for API endpoints
    
# Resource Limits
resources:
  maxMemoryUsage: "2GB"       # Memory limit for the application
  maxCpuUsage: "80%"          # CPU usage threshold
  
# Health Checks
health:
  enableHealthCheck: true
  healthCheckInterval: 30000  # 30 seconds health check
  gracefulShutdownTimeout: 10000  # 10 seconds graceful shutdown